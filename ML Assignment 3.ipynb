{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6k3UTi7t4oTg"
      },
      "outputs": [],
      "source": [
        "'''Q.1  What is Simple Linear Regression?'''"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " Simple Linear Regression is a statistical technique used to study the relationship between two variables:\n",
        "\n",
        "- One independent variable (X)\n",
        "\n",
        "- One dependent variable (Y)\n",
        "\n",
        "It shows how the value of Y changes based on changes in X by fitting a straight line (called the regression line) through the data points.\n",
        "\n",
        "Mathematical Equation:\n",
        "\n",
        "Y=a+bX\n",
        "\n",
        "Where:\n",
        "\n",
        "\n",
        "Y = Dependent variable\n",
        "\n",
        "\n",
        "X = Independent variable\n",
        "\n",
        "\n",
        "a = Intercept (value of Y when X = 0)\n",
        "\n",
        "\n",
        "b = Slope (rate of change in Y with respect to X)\n",
        "\n",
        "Purpose:\n",
        "\n",
        "- To predict the value of the dependent variable based on the independent variable.\n",
        "\n",
        "Example:\n",
        "\n",
        "- Predicting marks (Y) based on hours of study (X).\n",
        "\n",
        "Assumptions of Simple Linear Regression:\n",
        "\n",
        "- Linearity ‚Äì Relationship between X and Y is linear.\n",
        "\n",
        "- Independence ‚Äì Observations are independent.\n",
        "\n",
        "- Homoscedasticity ‚Äì Equal variance of errors.\n",
        "\n",
        "- Normality ‚Äì Errors follow a normal distribution.\n",
        "\n"
      ],
      "metadata": {
        "id": "hcvHHuJY5EHp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''Q.2 What are the key assumptions of Simple Linear Regression?'''"
      ],
      "metadata": {
        "id": "94lfPmEw6OMt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The key assumptions of Simple Linear Regression are:\n",
        "\n",
        "1. Linearity:\n",
        "\n",
        "There should be a linear relationship between the independent variable (X) and the dependent variable (Y).\n",
        "\n",
        "2. Independence:\n",
        "\n",
        "The observations (data points) should be independent of each other.\n",
        "This means one data point should not influence another.\n",
        "\n",
        "3. Homoscedasticity:\n",
        "\n",
        "The residuals (errors) should have constant variance across all levels of the independent variable.\n",
        "\n",
        "4. Normality of Errors:\n",
        "\n",
        "The residuals (differences between actual and predicted values) should be normally distributed.\n",
        "\n",
        "5. No Multicollinearity (only for Multiple Regression):\n",
        "\n",
        "Not applicable in Simple Linear Regression (since it involves only one independent variable), but important in multiple regression."
      ],
      "metadata": {
        "id": "9gHJjdkd6psi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''Q.3 What does the coefficient m represent in the equation Y=mX+c?'''"
      ],
      "metadata": {
        "id": "-w7_ZmG07B8M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the equation Y=mX+c, the coefficient 'm' represents the slope of the line.\n",
        "\n",
        "It shows the rate of change of Y with respect to X.\n",
        "\n",
        "Meaning:\n",
        "\n",
        "If\n",
        "m>0: Y increases as X increases (positive slope)\n",
        "\n",
        "If\n",
        "m<0: Y decreases as X increases (negative slope)\n",
        "\n",
        "If\n",
        "m=0: Y remains constant (horizontal line)\n",
        "\n",
        "Example:\n",
        "\n",
        "If\n",
        "Y=3X+2, then\n",
        "m=3.\n",
        "\n",
        "This means: for every 1 unit increase in X, Y increases by 3 units.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "UBeHw8cX7YiA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''Q.4  What does the intercept c represent in the equation Y=mX+c?'''"
      ],
      "metadata": {
        "id": "cC6LOr228GgF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the equation Y=mX+c, the intercept 'c' represents the value of Y when X = 0.\n",
        "\n",
        "It is called the Y-intercept ‚Äî the point where the line crosses the Y-axis.\n",
        "\n",
        "Meaning:\n",
        "\n",
        "- It shows the starting value or initial value of Y before any changes in X.\n",
        "\n",
        "- It helps in locating the position of the line on the graph.\n",
        "\n",
        "Example:\n",
        "If\n",
        "Y=2X+5,\n",
        "\n",
        "then:c=5\n",
        "\n",
        "This means when\n",
        "X=0,\n",
        "Y=5\n",
        "\n"
      ],
      "metadata": {
        "id": "TPJOvQNX8Pqp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''Q.5 How do we calculate the slope m in Simple Linear Regression?'''"
      ],
      "metadata": {
        "id": "PtUFlQ6r8530"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "In Simple Linear Regression, the slope $m$ is calculated using the formula:\n",
        "\n",
        "$$\n",
        "m = \\frac{n(\\sum XY) - (\\sum X)(\\sum Y)}{n(\\sum X^2) - (\\sum X)^2}\n",
        "$$\n",
        "\n",
        "Where:\n",
        "\n",
        "* $n$ = number of data points\n",
        "* $\\sum XY$ = sum of the product of X and Y values\n",
        "* $\\sum X$ = sum of X values\n",
        "* $\\sum Y$ = sum of Y values\n",
        "* $\\sum X^2$ = sum of squares of X values\n",
        "\n",
        "\n",
        "\n",
        "Purpose of 'm':\n",
        "\n",
        "* It tells us how much Y changes for a unit change in X.\n",
        "* It is the slope of the best-fit line.\n",
        "\n",
        "\n",
        "\n",
        "Example:\n",
        "\n",
        "Given data:\n",
        "X: 1, 2, 3\n",
        "Y: 2, 4, 5\n",
        "\n",
        "Apply the formula using calculated sums.\n",
        "\n"
      ],
      "metadata": {
        "id": "qhYcov1Q9HIw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''Q.6 What is the purpose of the Least Squares Method in Simple Linear Regression?'''"
      ],
      "metadata": {
        "id": "ZH-zac7h-pwa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The purpose of the Least Squares Method is to find the best-fitting straight line through the data points by minimizing the sum of the squared differences between actual and predicted values.\n",
        "\n",
        "These differences are called residuals (errors).\n",
        "\n",
        "In short:\n",
        "\n",
        "- The Least Squares Method minimizes the total error and gives the most accurate line (regression line) for prediction.\n",
        "\n",
        "Formula it tries to minimize:\n",
        "\n",
        "$$\n",
        "\\sum (Y_i - \\hat{Y}_i)^2\n",
        "$$\n",
        "\n",
        "Where:\n",
        "\n",
        "* $Y_i$ = Actual value\n",
        "* $\\hat{Y}_i$ = Predicted value\n",
        "* $(Y_i - \\hat{Y}_i)^2$ = Squared error (residual)\n",
        "\n",
        "Result:\n",
        "\n",
        "Using this method, we calculate the slope (m) and intercept (c) of the line $Y = mX + c$.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "OtdH0d-MANPF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''Q.7 How is the coefficient of determination (R¬≤) interpreted in Simple Linear Regression?'''"
      ],
      "metadata": {
        "id": "F-Np5pkqA3g6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Coefficient of Determination, denoted as $R^2$, measures how well the regression line fits the data.\n",
        "\n",
        "It tells us the proportion of the variance in the dependent variable (Y) that is explained by the independent variable (X).\n",
        "\n",
        "Interpretation of $R^2$:\n",
        "\n",
        "* $R^2 = 1$ ‚Üí Perfect fit (100% of the variance in Y is explained by X)\n",
        "* $R^2 = 0$ ‚Üí No fit (X explains 0% of the variance in Y)\n",
        "* $0 < R^2 < 1$ ‚Üí Partial fit (some of the variance is explained)\n",
        "\n",
        "\n",
        "Example:\n",
        "\n",
        "- If $R^2 = 0.85$, it means 85% of the variation in Y is explained by X, and 15% is unexplained.\n",
        "\n",
        "\n",
        "\n",
        "Formula (for reference):\n",
        "\n",
        "$$\n",
        "R^2 = 1 - \\frac{SS_{\\text{res}}}{SS_{\\text{tot}}}\n",
        "$$\n",
        "\n",
        "Where:\n",
        "\n",
        "* $SS_{\\text{res}}$: Sum of squares of residuals\n",
        "* $SS_{\\text{tot}}$: Total sum of squares\n",
        "\n",
        "Tip:\n",
        "* Higher the $R^2$, better the model‚Äôs performance.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "blBa9PNTBDGt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''Q.8 What is Multiple Linear Regression?'''"
      ],
      "metadata": {
        "id": "L5dF2FkiCL_Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "Multiple Linear Regression is a statistical method used to study the relationship between one dependent variable (Y) and two or more independent variables (X‚ÇÅ, X‚ÇÇ, ..., X‚Çô).\n",
        "\n",
        "It is an extension of Simple Linear Regression, which involves only one independent variable.\n",
        "\n",
        "Mathematical Equation:\n",
        "\n",
        "$$\n",
        "Y = a + b_1X_1 + b_2X_2 + \\dots + b_nX_n\n",
        "$$\n",
        "\n",
        "Where:\n",
        "\n",
        "* $Y$ = Dependent variable\n",
        "* $X_1, X_2, ..., X_n$ = Independent variables\n",
        "* $a$ = Intercept\n",
        "* $b_1, b_2, ..., b_n$ = Coefficients (slopes for each X)\n",
        "\n",
        "Purpose:\n",
        "\n",
        "To predict the value of Y based on multiple factors (X‚ÇÅ, X‚ÇÇ, ..., X‚Çô) and to understand how each variable influences Y.\n",
        "\n",
        "Example:\n",
        "\n",
        "Predicting a student's exam score (Y) based on:\n",
        "\n",
        "* Hours studied (X‚ÇÅ)\n",
        "* Sleep hours (X‚ÇÇ)\n",
        "* Number of practice tests taken (X‚ÇÉ)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "_i8iZBbmCcPh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''Q.9 What is the main difference between Simple and Multiple Linear Regression?'''"
      ],
      "metadata": {
        "id": "has-7JsNUvjv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "| **Aspect**                          | **Simple Linear Regression**       | **Multiple Linear Regression**                             |\n",
        "| ----------------------------------- | ---------------------------------- | ---------------------------------------------------------- |\n",
        "| Number of Independent Variables | Only one independent variable  | Two or more independent variables                      |\n",
        "| Equation                     | $Y = b_0 + b_1X + \\varepsilon$     | $Y = b_0 + b_1X_1 + b_2X_2 + \\dots + b_nX_n + \\varepsilon$ |\n",
        "| Complexity                      | Less complex, easy to visualize    | More complex, harder to visualize in higher dimensions     |\n",
        "| Use Case                     | When one factor affects the target | When multiple factors affect the target                    |\n"
      ],
      "metadata": {
        "id": "-TDaGSUZU7bb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''Q.10 What are the key assumptions of Multiple Linear Regression?'''"
      ],
      "metadata": {
        "id": "CiUHW5BkVU9q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Linearity\n",
        "\n",
        "- There is a linear relationship between the dependent variable and each independent variable.\n",
        "\n",
        "2. Independence of Errors\n",
        "\n",
        "- The residuals (errors) are independent of each other.\n",
        "\n",
        "- Often tested using the Durbin-Watson test.\n",
        "\n",
        "3. Homoscedasticity\n",
        "\n",
        "- The variance of errors is constant across all levels of independent variables.\n",
        "\n",
        "- No pattern in the residual plot.\n",
        "\n",
        "4. Normality of Errors\n",
        "\n",
        "- The residuals should be normally distributed.\n",
        "\n",
        "- Can be checked using a histogram or Q-Q plot.\n",
        "\n",
        "5. No Multicollinearity\n",
        "\n",
        "- The independent variables should not be highly correlated with each other.\n",
        "\n",
        "- Tested using VIF (Variance Inflation Factor).\n",
        "\n"
      ],
      "metadata": {
        "id": "ANwlxsiQVjKE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''Q.11 What is heteroscedasticity, and how does it affect the results of a Multiple Linear Regression model?'''"
      ],
      "metadata": {
        "id": "pCxsjQm5WBEq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Heteroscedasticity occurs when the variance of the error terms (residuals) is not constant across all levels of the independent variables in a regression model.\n",
        "\n",
        "- Impact on Multiple Linear Regression:\n",
        "\n",
        "- Violates the assumption of homoscedasticity.\n",
        "\n",
        "- Leads to inefficient estimates of coefficients.\n",
        "\n",
        "- Standard errors become unreliable, which affects:\n",
        "\n",
        " - t-tests (for significance)\n",
        "\n",
        " - Confidence intervals\n",
        "\n",
        "- It can result in incorrect conclusions about which variables are important.\n",
        "\n",
        "How to Detect It:\n",
        "\n",
        "- Residual vs Fitted plot: If the spread of residuals increases or decreases with fitted values, heteroscedasticity is present.\n",
        "\n",
        "- Statistical tests:\n",
        "\n",
        " - Breusch-Pagan test\n",
        "\n",
        " - White‚Äôs test\n",
        "\n"
      ],
      "metadata": {
        "id": "xj3w81uFWJKG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''Q.12 How can you improve a Multiple Linear Regression model with high multicollinearity?'''"
      ],
      "metadata": {
        "id": "bAlQglGWWzEZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Multicollinearity means two or more independent variables are highly correlated, which can make regression coefficients unstable and unreliable.\n",
        "\n",
        " Ways to Improve the Model:\n",
        "\n",
        "1. Remove Highly Correlated Predictors\n",
        "\n",
        "- Drop one of the variables that are highly correlated.\n",
        "\n",
        "- Use a correlation matrix to identify such variables.\n",
        "\n",
        "2. Use Principal Component Analysis (PCA)\n",
        "\n",
        "- Converts correlated variables into a set of uncorrelated components.\n",
        "\n",
        "3. Combine Variables\n",
        "\n",
        "- If two variables are highly correlated and measure similar things, combine them into one (e.g., average or ratio).\n",
        "\n",
        "4. Regularization Techniques\n",
        "\n",
        "- Use models like Ridge Regression or Lasso Regression which handle multicollinearity by adding a penalty term.\n",
        "\n",
        "5. Check Variance Inflation Factor (VIF)\n",
        "\n",
        "-  Remove variables with high VIF values (typically > 5 or 10).\n",
        "\n"
      ],
      "metadata": {
        "id": "VGheWNyAW3Ln"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''Q.13 What are some common techniques for transforming categorical variables for use in regression models?'''"
      ],
      "metadata": {
        "id": "gY0Tp4gVv2Oo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "| **Technique**                | **Description**                                                                                                               |\n",
        "| ---------------------------- | ----------------------------------------------------------------------------------------------------------------------------- |\n",
        "| One-Hot Encoding         | Converts each category into a separate binary column (0 or 1). Avoid dummy variable trap by removing one column.              |\n",
        "| Label Encoding           | Assigns a unique number to each category. Best for ordinal data (e.g., low = 1, medium = 2, high = 3).                    |\n",
        "| Ordinal Encoding         | Like label encoding, but explicitly used when categories have a meaningful order.                                             |\n",
        "| Binary Encoding          | Converts categories into binary numbers and splits into columns. Efficient for high-cardinality features.                     |\n",
        "|\n",
        "Frequency/Count Encoding | Replaces categories with the frequency or count of their occurrences in the data.                                             |\n",
        "| Target Encoding          | Replaces each category with the mean of the target variable for that category (used with caution due to risk of overfitting). |\n"
      ],
      "metadata": {
        "id": "N4XqQHILwmoE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''Q.14 What is the role of interaction terms in Multiple Linear Regression?'''"
      ],
      "metadata": {
        "id": "MKE1x8kFZwE6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Interaction terms in Multiple Linear Regression are used to model the combined effect of two or more independent variables on the dependent variable.\n",
        "\n",
        "Definition:\n",
        "\n",
        "An interaction term is created by multiplying two (or more) independent variables together to see if their joint effect on the dependent variable is different from their individual effects.\n",
        "\n",
        "Why Use Interaction Terms?\n",
        "\n",
        "- To capture relationships between variables that only exist when considered together.\n",
        "\n",
        "- Helps when the effect of one variable depends on the level of another.\n",
        "\n",
        "Example Equation with Interaction Term:\n",
        "Y=b\n",
        "0\n",
        "‚Äã\n",
        " +b\n",
        "1\n",
        "‚Äã\n",
        " X\n",
        "1\n",
        "‚Äã\n",
        " +b\n",
        "2\n",
        "‚Äã\n",
        " X\n",
        "2\n",
        "‚Äã\n",
        " +b\n",
        "3\n",
        "‚Äã\n",
        " (X\n",
        "1\n",
        "‚Äã\n",
        " √óX\n",
        "2\n",
        "‚Äã\n",
        " )+Œµ\n",
        "\n",
        " Here,\n",
        "b\n",
        "3\n",
        "‚Äã captures the interaction effect between\n",
        "X\n",
        "1\n",
        "‚Äã\n",
        "  and\n",
        "X\n",
        "2\n",
        "‚Äã\n",
        " .\n",
        "\n"
      ],
      "metadata": {
        "id": "xHTiP6YFaY2W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''Q.15 How can the interpretation of intercept differ between Simple and Multiple Linear Regression?'''"
      ],
      "metadata": {
        "id": "cOTW7t83bnib"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.In Simple Linear Regression:\n",
        "\n",
        "* The intercept (b‚ÇÄ) represents the expected value of the dependent variable (Y) when the independent variable (X) is zero.\n",
        "\n",
        "$$\n",
        "Y = b_0 + b_1X\n",
        "$$\n",
        "\n",
        "* Interpretation:\n",
        "\n",
        "> When $X = 0$, the value of $Y$ is equal to the intercept $b_0$.\n",
        "\n",
        "\n",
        "\n",
        "2.In Multiple Linear Regression:\n",
        "\n",
        "* The intercept (b‚ÇÄ) represents the expected value of the dependent variable (Y) when all independent variables are zero.\n",
        "\n",
        "$$\n",
        "Y = b_0 + b_1X_1 + b_2X_2 + \\dots + b_nX_n\n",
        "$$\n",
        "\n",
        "* Interpretation:\n",
        "\n",
        "> When $X_1 = X_2 = \\dots = X_n = 0$, the value of $Y$ is equal to the intercept $b_0$.\n",
        "\n",
        "Important Note:\n",
        "\n",
        "* In Multiple Linear Regression, the intercept often has no real-world meaning if zero is not a possible or meaningful value for all predictors.\n",
        "\n",
        "\n",
        "Short Answer:\n",
        "\n",
        "* In Simple Linear Regression, the intercept is the predicted value of Y when X = 0.\n",
        "* In Multiple Linear Regression, it is the predicted value of Y when all independent variables are 0.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "7pMytiy5bmUm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''Q.16 What is the significance of the slope in regression analysis, and how does it affect predictions?'''"
      ],
      "metadata": {
        "id": "pfRByAXYdFAw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Definition of Slope:\n",
        "\n",
        "In regression analysis, the slope (coefficient of an independent variable) represents the rate of change in the dependent variable (Y) for a one-unit increase in the independent variable (X), keeping all other variables constant.\n",
        "\n",
        "Significance of Slope:\n",
        "\n",
        "* Shows the direction and strength of the relationship between variables:\n",
        "\n",
        "  * Positive slope ‚Üí As $X$ increases, $Y$ increases.\n",
        "  * Negative slope ‚Üí As $X$ increases, $Y$ decreases.\n",
        "* Helps in understanding how strongly a predictor affects the outcome.\n",
        "* The magnitude of the slope shows how much change is expected in the dependent variable.\n",
        "\n",
        "Impact on Predictions:\n",
        "\n",
        "* The slope directly affects the predicted values of $Y$.\n",
        "* In a regression equation:\n",
        "\n",
        "  $$\n",
        "  Y = b_0 + b_1X\n",
        "  $$\n",
        "\n",
        "  The value of $b_1$ (slope) tells us how much $Y$ will change when $X$ increases by 1 unit.\n",
        "\n",
        "Short Answer:\n",
        "\n",
        "> The slope in regression analysis indicates how much the dependent variable changes for a one-unit change in the independent variable. It affects predictions by determining the direction and amount of change in the predicted value.\n",
        "\n"
      ],
      "metadata": {
        "id": "OEYD9YrMdWP0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''Q.17 How does the intercept in a regression model provide context for the relationship between variables?'''"
      ],
      "metadata": {
        "id": "jEIkAM_7d4z-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "Definition of Intercept:\n",
        "\n",
        "In a regression model, the intercept (b‚ÇÄ) is the value of the dependent variable (Y) when all independent variables (X) are equal to zero.\n",
        "\n",
        "Contextual Role of Intercept:\n",
        "\n",
        "* It provides a starting point or baseline for the regression equation.\n",
        "* Helps understand the value of the outcome variable when no predictors are present.\n",
        "* Example:\n",
        "  If the equation is:\n",
        "\n",
        "  $$\n",
        "  Y = b_0 + b_1X_1 + b_2X_2\n",
        "  $$\n",
        "\n",
        "  Then $b_0$ tells us the expected value of $Y$ when $X_1 = X_2 = 0$.\n",
        "\n",
        "\n",
        "Important Notes:\n",
        "\n",
        "* The intercept may not always be meaningful, especially if zero is not a realistic value for all predictors.\n",
        "* Even if not interpretable, it is mathematically necessary to accurately fit the model.\n",
        "\n",
        "Short Answer:\n",
        "\n",
        "> The intercept shows the expected value of the dependent variable when all independent variables are zero. It provides a baseline to understand how predictors influence the outcome.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "NPZ6mxMtesI3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''Q.18 What are the limitations of using R¬≤ as a sole measure of model performance?'''"
      ],
      "metadata": {
        "id": "jcVUPQ8kfWGd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "| **Aspect**                              | **Limitation of R¬≤**                                                                  |\n",
        "| --------------------------------------- | ------------------------------------------------------------------------------------- |\n",
        "| Doesn't Detect Overfitting          | A high R¬≤ may occur even when the model is overfitting** the training data.         |\n",
        "| Doesn‚Äôt Show Causality              | R¬≤ only shows correlation, not causation** between variables.                       |\n",
        "| Affected by Number of Predictors    | Adding more variables can artificially increase R¬≤, even if they are irrelevant.  |\n",
        "| Ignores Model Bias                  | R¬≤ does not account for whether the model‚Äôs predictions are systematically wrong. |\n",
        "| Not Suitable for Non-Linear Models  | R¬≤ may give misleading results for non-linear relationships.                      |\n",
        "| Doesn‚Äôt Reflect Prediction Accuracy | A high R¬≤ doesn‚Äôt always mean the model predicts well on new/unseen data.         |\n"
      ],
      "metadata": {
        "id": "r554Dq2Gfl7I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''Q.19 How would you interpret a large standard error for a regression coefficient?'''"
      ],
      "metadata": {
        "id": "aGWGMq8jgF88"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "| **Aspect**                     | **Interpretation**                                                                                                                 |\n",
        "| ------------------------------ | ---------------------------------------------------------------------------------------------------------------------------------- |\n",
        "| Definition                 | The standard error of a regression coefficient measures the variability of the estimated coefficient across different samples. |\n",
        "| Large Standard Error Means | The coefficient estimate is not precise ‚Äî it varies widely from sample to sample.                                              |\n",
        "| Impact on Significance     | A large standard error makes the t-statistic small, which may lead to a high p-value.                                      |\n",
        "| Conclusion                 | The predictor may not be statistically significant, and we may not trust its effect on the dependent variable.             |\n",
        "| Possible Causes            | - Multicollinearity                                                                                                                |\n",
        "\n",
        "* Small sample size\n",
        "* High data variability\n",
        "* Poor model fit  |\n",
        "\n",
        "Short Answer:\n",
        "\n",
        "> A large standard error for a regression coefficient indicates low precision and suggests that the variable may not have a significant impact on the dependent variable.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "2-dZ2CKcgn_g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''Q.20 How can heteroscedasticity be identified in residual plots, and why is it important to address it?'''"
      ],
      "metadata": {
        "id": "DZ1yW5zohPK0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Identification in Residual Plots:\n",
        "\n",
        "- In a residual vs fitted values plot, heteroscedasticity appears as:\n",
        "\n",
        " - A funnel shape (widening or narrowing spread of residuals).\n",
        "\n",
        " - A patterned spread, rather than a constant horizontal band.\n",
        "\n",
        " Constant spread = Homoscedasticity (good)\n",
        "\n",
        " Varying spread = Heteroscedasticity (problem)\n",
        "\n",
        "Why It's Important to Address Heteroscedasticity:\n",
        "\n",
        "| Reason                               | Explanation                                                              |\n",
        "| ---------------------------------------- | ---------------------------------------------------------------------------- |\n",
        "| Violates regression assumptions      | Breaks the assumption of constant variance of errors (homoscedasticity). |\n",
        "| Unreliable standard errors           | Leads to incorrect p-values, t-tests, and confidence intervals.  |\n",
        "| Affects model accuracy and inference | Can result in misleading conclusions about variable significance.        |\n",
        "\n"
      ],
      "metadata": {
        "id": "7zteT6YFhtWW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''Q.21 What does it mean if a Multiple Linear Regression model has a high R¬≤ but low adjusted R¬≤?'''"
      ],
      "metadata": {
        "id": "S7RhPIn1inbR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "| Term           | Meaning                                                                           |\n",
        "| ------------------ | ------------------------------------------------------------------------------------- |\n",
        "| R¬≤ (R-squared) | Measures the proportion of variance in the dependent variable explained by the model. |\n",
        "| Adjusted R¬≤    | Adjusts R¬≤ for the number of predictors, penalizing irrelevant variables.         |\n",
        "\n",
        "Interpretation:\n",
        "\n",
        "If a model has high R¬≤ but low Adjusted R¬≤, it means:\n",
        "\n",
        "- The model includes too many predictors, some of which do not contribute meaningfully.\n",
        "\n",
        "- The high R¬≤ is inflated by adding unnecessary variables.\n",
        "\n",
        "- The model may be overfitting ‚Äî fitting noise instead of true signal.\n",
        "\n",
        "Why It Matters:\n",
        "\n",
        "- A high R¬≤ alone can be misleading.\n",
        "\n",
        "- Adjusted R¬≤ helps determine the true explanatory power of the model after removing the effect of irrelevant predictors.\n",
        "\n",
        "Short Answer:\n",
        "\n",
        "A high R¬≤ but low adjusted R¬≤ indicates that the model includes unnecessary variables, reducing its reliability and possibly leading to overfitting."
      ],
      "metadata": {
        "id": "346ZuxNDircF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''Q.22 Why is it important to scale variables in Multiple Linear Regression?'''"
      ],
      "metadata": {
        "id": "WTwbpEqWlDtr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Definition of Scaling:\n",
        "\n",
        "Scaling means standardizing the range of independent variables, usually by normalization or standardization (e.g., converting values to z-scores).\n",
        "\n",
        "Importance of Scaling in Multiple Linear Regression:\n",
        "\n",
        "| **Reason**                            | **Explanation**                                                                          |\n",
        "| ------------------------------------- | ---------------------------------------------------------------------------------------- |\n",
        "| Improves numerical stability    | Scaling reduces large differences in variable magnitudes, avoiding calculation errors.   |\n",
        "| Makes coefficients comparable  | Allows us to compare the relative impact of each variable on the dependent variable. |\n",
        "| Supports regularization methods | Methods like Ridge and Lasso require scaling to apply penalties correctly.           |\n",
        "| Improves model interpretation   | Easier to interpret how much 1 standard unit change in X affects Y.                  |\n",
        "\n",
        " When It's Less Critical:\n",
        "\n",
        "- Scaling is not mandatory for basic regression without regularization.\n",
        "\n",
        "- But it's very helpful when predictors are on very different scales (e.g., age vs income).\n",
        "\n",
        "Short Answer:\n",
        "\n",
        "Scaling variables helps improve model stability, makes coefficients interpretable, and is essential for regularization techniques like Ridge and Lasso."
      ],
      "metadata": {
        "id": "pWiHOyS6l06o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''Q.23 What is polynomial regression?'''"
      ],
      "metadata": {
        "id": "5qeGOoifmjN-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Definition:\n",
        "\n",
        "Polynomial Regression is a type of regression analysis where the relationship between the independent variable (X) and the dependent variable (Y) is modeled as an nth-degree polynomial.\n",
        "\n",
        "It is used when the data shows a non-linear trend, but we still want to use a regression-based approach.\n",
        "\n",
        " General Equation:\n",
        "\n",
        "ùëå\n",
        "=\n",
        "ùëè\n",
        "0\n",
        "+\n",
        "ùëè\n",
        "1\n",
        "ùëã\n",
        "+\n",
        "ùëè\n",
        "2\n",
        "ùëã^\n",
        "2\n",
        "+\n",
        "ùëè\n",
        "3\n",
        "ùëã^\n",
        "3\n",
        "+\n",
        "‚ãØ\n",
        "+\n",
        "ùëè\n",
        "ùëõ\n",
        "ùëã^\n",
        "ùëõ\n",
        "+\n",
        "ùúÄ\n",
        "\n",
        "ùëå= Dependent variable\n",
        "\n",
        "ùëã= Independent variable\n",
        "\n",
        "ùëè\n",
        "0\n",
        ",\n",
        "ùëè\n",
        "1\n",
        ",\n",
        "‚Ä¶\n",
        ",\n",
        "ùëè\n",
        "ùëõ= Coefficients\n",
        "\n",
        "ùúÄ = Error term\n",
        "\n",
        "ùëõ = Degree of the polynomial\n",
        "\n",
        "Key Points:\n",
        "\n",
        "| **Feature**                          | **Explanation**                                                     |\n",
        "| ------------------------------------ | ------------------------------------------------------------------- |\n",
        "| Non-linear modeling              | Models curved relationships using polynomial terms.                 |\n",
        "| Still linear in parameters       | Despite non-linear form, it's linear in terms of coefficients.      |\n",
        "| Higher-degree = more flexibility | Higher degrees can capture more complex patterns (but may overfit). |\n"
      ],
      "metadata": {
        "id": "SKA-m4X-nH-Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''Q.24 How does polynomial regression differ from linear regression?'''"
      ],
      "metadata": {
        "id": "dszdffM6on-3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "| **Aspect**               | **Linear Regression**                     | **Polynomial Regression**                                         |\n",
        "| ------------------------ | ----------------------------------------- | ----------------------------------------------------------------- |\n",
        "| Equation Form        | $Y = b_0 + b_1X + \\varepsilon$            | $Y = b_0 + b_1X + b_2X^2 + b_3X^3 + \\dots + b_nX^n + \\varepsilon$ |\n",
        "| Relationship Modeled | Models a straight-line relationship   | Models a curved or non-linear relationship                    |\n",
        "| Linearity            | Linear in both X and coefficients | Linear in coefficients, but non-linear in X               |\n",
        "| Complexity          | Simple and easy to interpret              | More complex; higher degree may lead to overfitting           |\n",
        "| Use Case            | When the data shows a linear trend    | When the data shows a non-linear pattern                     |\n"
      ],
      "metadata": {
        "id": "xu3-WdnGoy3U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''Q.25 When is polynomial regression used?'''"
      ],
      "metadata": {
        "id": "sOlBsI7BpTrR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Definition:\n",
        "\n",
        "Polynomial Regression is used to model a non-linear relationship between the independent variable and the dependent variable using a polynomial equation.\n",
        "\n",
        "Situations Where It Is Used:\n",
        "\n",
        "| **Scenario**                   | **Explanation**                                                               |\n",
        "| ------------------------------ | ----------------------------------------------------------------------------- |\n",
        "| Non-linear data patterns | When the relationship between X and Y is curved, not a straight line.         |\n",
        "| Improving model fit     | When linear regression shows poor fit (low R¬≤), and residuals show a pattern. |\n",
        "| Real-world phenomena     | Used in physics, economics, biology, etc., where changes occur non-linearly.  |\n",
        "| Trend analysis           | Useful for modeling growth, decay, or cyclical trends in data.    |\n",
        "| Visual curve fitting     | When visual inspection suggests a curved pattern (e.g., U-shape or S-shape).  |\n"
      ],
      "metadata": {
        "id": "LFmn8P_Mpb15"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''Q.26 What is the general equation for polynomial regression?'''"
      ],
      "metadata": {
        "id": "DZzvGo2rqCg_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "General Form of Polynomial Regression:\n",
        "\n",
        "$$\n",
        "Y = b_0 + b_1X + b_2X^2 + b_3X^3 + \\dots + b_nX^n + \\varepsilon\n",
        "$$\n",
        "\n",
        "\n",
        "Where:\n",
        "\n",
        "* $Y$ = Dependent variable\n",
        "* $X$ = Independent variable\n",
        "* $b_0$ = Intercept\n",
        "* $b_1, b_2, \\dots, b_n$ = Coefficients for each degree of $X$\n",
        "* $X^2, X^3, \\dots, X^n$ = Polynomial (non-linear) terms\n",
        "* $\\varepsilon$ = Error term\n",
        "* $n$ = Degree of the polynomial\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "9TJi_n8aqGI9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''Q.27 Can polynomial regression be applied to multiple variables?'''"
      ],
      "metadata": {
        "id": "pY2NEIjcqY35"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "YES, polynomial regression can be applied to multiple independent variables.\n",
        "\n",
        "This is known as Multivariate Polynomial Regression or Polynomial Multiple Linear Regression.\n",
        "\n",
        "Explanation:\n",
        "\n",
        "When you have more than one input variable, polynomial regression includes:\n",
        "\n",
        "* Individual powers of each variable\n",
        "* Interaction terms (e.g., $X_1X_2$, $X_1^2X_2$, etc.)\n",
        "\n",
        "Example Equation (2 variables, degree 2):\n",
        "\n",
        "$$\n",
        "Y = b_0 + b_1X_1 + b_2X_2 + b_3X_1^2 + b_4X_2^2 + b_5X_1X_2 + \\varepsilon\n",
        "$$\n",
        "\n",
        "Use Case:\n",
        "\n",
        "Used when the relationship between multiple variables and the outcome is non-linear and complex."
      ],
      "metadata": {
        "id": "5LGKMQ1zqs_5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''Q.28 What are the limitations of polynomial regression?'''"
      ],
      "metadata": {
        "id": "TlDvJLf6rPN4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "| **Limitation**                   | **Explanation**                                                                                    |\n",
        "| -------------------------------- | -------------------------------------------------------------------------------------------------- |\n",
        "| Overfitting                  | High-degree polynomials may fit the training data too closely and perform poorly on new data.      |\n",
        "| Complexity Increases Rapidly | As the degree increases, the model becomes harder to interpret and manage.                         |\n",
        "| Sensitive to Outliers        | A few extreme data points can drastically affect the curve and model accuracy.                     |\n",
        "| Risk of Multicollinearity   | Polynomial terms (like $X$, $X^2$, $X^3$) are often correlated, affecting coefficient reliability. |\n",
        "| Poor Extrapolation           | Predictions outside the data range can be highly inaccurate.                                       |\n",
        "| Computational Cost           | Higher-degree polynomial models require more processing power and memory.                          |\n"
      ],
      "metadata": {
        "id": "Yr6yBjNwrb9e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''Q.29 What methods can be used to evaluate model fit when selecting the degree of a polynomial?'''"
      ],
      "metadata": {
        "id": "FW02k4DFru6i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Key Methods to Evaluate and Select the Degree of a Polynomial Regression Model:\n",
        "\n",
        "\n",
        "| **Method**                                      | **Explanation**                                                                                                 |\n",
        "| ----------------------------------------------- | --------------------------------------------------------------------------------------------------------------- |\n",
        "| R¬≤ (R-squared)                              | Measures how much variance in the dependent variable is explained by the model. Higher R¬≤ indicates better fit. |\n",
        "| Adjusted R¬≤                                | Penalizes unnecessary predictors. Helps identify the optimal degree without overfitting.                        |\n",
        "| Mean Squared Error (MSE)                    | Measures the average squared difference between actual and predicted values. Lower MSE indicates better fit.    |\n",
        "| Root Mean Squared Error (RMSE)              | Square root of MSE; easier to interpret in terms of original units.                                             |\n",
        "| Cross-Validation (e.g., k-fold)             | Splits data into training and validation sets to test how well the model generalizes to new data.               |\n",
        "| AIC / BIC (Akaike / Bayesian Info Criteria) | Balance goodness of fit and model complexity. Lower values suggest a better model.                              |\n",
        "| Residual Plots                              | Visual inspection to detect non-random patterns. A good fit shows random scatter of residuals.                  |\n"
      ],
      "metadata": {
        "id": "Dfo-lMbor7_e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''Q.30 Why is visualization important in polynomial regression?'''"
      ],
      "metadata": {
        "id": "HCcslBXFsiBx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "| **Reason**                              | **Explanation**                                                                   |\n",
        "| --------------------------------------- | --------------------------------------------------------------------------------- |\n",
        "| Understanding Non-linear Patterns | Helps to clearly see the curve or trend captured by the polynomial model.     |\n",
        "| Model Fit Assessment              | Visualizes how well the model fits the actual data (underfitting or overfitting). |\n",
        "| Compare Different Degrees         | Shows how the shape of the curve changes as the polynomial degree increases.  |\n",
        "| Detect Overfitting                | Overly wiggly or complex curves in the plot may indicate overfitting.         |\n",
        "| Communicating Results             | Easier to explain model behavior and findings to others using visual graphs.  |\n",
        "\n",
        "Typical Visuals Used:\n",
        "\n",
        "- Scatter plot of data points with polynomial regression curve.\n",
        "\n",
        "- Residual plots to check randomness of errors."
      ],
      "metadata": {
        "id": "0X8CTEE0sk_O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''Q.31 How is polynomial regression implemented¬†in¬†Python?'''"
      ],
      "metadata": {
        "id": "smEwtBr-uhLh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Import required libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Step 2: Sample data\n",
        "X = np.array([1, 2, 3, 4, 5]).reshape(-1, 1)\n",
        "y = np.array([1, 4, 9, 16, 25])  # y = x^2, perfect quadratic\n",
        "\n",
        "# Step 3: Transform input data to polynomial features (degree 2)\n",
        "poly = PolynomialFeatures(degree=2)\n",
        "X_poly = poly.fit_transform(X)\n",
        "\n",
        "# Step 4: Fit the model\n",
        "model = LinearRegression()\n",
        "model.fit(X_poly, y)\n",
        "\n",
        "# Step 5: Predict using the model\n",
        "y_pred = model.predict(X_poly)\n",
        "\n",
        "# Step 6: Visualize the results\n",
        "plt.scatter(X, y, color='blue', label='Actual')\n",
        "plt.plot(X, y_pred, color='red', label='Polynomial Fit')\n",
        "plt.title('Polynomial Regression (Degree 2)')\n",
        "plt.xlabel('X')\n",
        "plt.ylabel('y')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Step 7: Evaluate the model\n",
        "mse = mean_squared_error(y, y_pred)\n",
        "print(\"Mean Squared Error:\", mse)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 489
        },
        "id": "VnE6NDnuuxPU",
        "outputId": "1aa81ec7-46d3-4700-e7c9-c169e00c7bdd"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error: 1.5146129380243426e-29\n"
          ]
        }
      ]
    }
  ]
}